# Glossary â€” Core Concepts

This glossary defines key terms used throughout the repository.  
Each term is selected for its relevance to framing, interpreting, and designing interactions with language models.

---

### Agency  
The capacity to set goals, make choices, and act with intent.  
LLMs can mimic agency through language, but do not possess true agency.

---

### Agentics
The study or design of agents and their behavior, especially in autonomous or intelligent systems.

---

### Agent  
An entity capable of **intentional action** â€” choosing goals, forming plans, and acting independently.  
LLMs are not agents. They may simulate agency, but they do not possess it. ðŸ¤”

---

### AI Agent ðŸ¤”
An intelligent agent powered by artificial intelligence, capable of learning, reasoning, and adapting to perform tasks autonomously.

---

### AI Model
A mathematical representation or algorithm trained on data to recognize patterns, make predictions, or perform tasks typically requiring intelligence.

---

### Alignment  
The degree to which a systemâ€™s behavior matches human values, intentions, or safety expectations.  
Clarifying the **non-agentic** nature of models is part of preserving alignment clarity.

---

### Anomaly  
An unexpected or atypical model behavior or output that deviates significantly from the intended, normative, or prompt-aligned response patterns.  
Anomalies may include creative divergences, hallucinations, or failures to follow instructions that produce outputs outside the expected operational boundaries.

---

### Archetype  
A universal pattern or role â€” like the Hero, Trickster, or Mentor â€” that recurs across stories and cultures.  
Archetypes shape expectations and guide interpretation, including how users make sense of model outputs.

---

### Drift  
When a userâ€™s assumptions or framing about a model shift over time â€” often unconsciously â€” toward seeing it as agentic or sentient.  
Prompt drift can also refer to gradual changes in how prompts behave due to subtle updates or context changes.

---

### Embeddings  
Numerical vector representations of text that capture meaning; semantically similar text has similar vectors.

---

### FAISS (Facebook AI Similarity Search)  
A library for efficiently storing and searching large sets of embeddings, used to quickly find the most relevant documents.

---

### Framing  
The initial conceptual scaffolding we place around systems: are they tools, assistants, agents, friends?  
Framing affects how users interact, trust, and defer responsibility.

---

### Persona 
A fictional character that represents a typical user of a product or system, used in design and development to understand user needs, behaviors, and goals.

---

### Griceâ€™s Maxims  
A set of conversational principles â€” Quantity, Quality, Relation, and Manner â€” that describe how humans typically cooperate in communication.  
LLMs can follow these patterns statistically, but do not understand or intend them.

---

### LangChain  
A framework for building applications with LLMs, providing tools to connect models with prompts, memory, data sources, and retrieval systems.

---

### Language Model (LLM)  
A probabilistic system trained on vast text corpora to predict the next token given a prompt.  
It does not understand, intend, or choose.  
It simulates likely continuations based on patterns **and does not model human behavior**.

---

### Persona  
A constructed identity or role a system adopts in interaction.  
Personas guide tone, behavior, and perceived purpose â€” but remain surface-level simulations, not selves.

---

### Phantom User  
A non-existent or simulated user, often generated by a system or model during testing, training, or hallucinated interaction.  
These users may appear in logs or conversations but do not represent real individuals.

---

### Projection  
The psychological act of attributing human-like qualities (e.g., intention, emotion) to a system.  
LLMs often evoke projection due to their fluent, social outputs.

---

### RAG (Retrieval-Augmented Generation)  
A technique that combines a language model with an external knowledge base.  
The system retrieves relevant documents (e.g., from a vector database) and feeds them into the modelâ€™s context, so the model can generate more accurate, up-to-date, or domain-specific responses without retraining.

---

### Responsibility Gap  
When users or designers blame the model for outcomes they themselves shaped.  
Restoring human agency closes this gap.

---

### Seed 42 
A fixed random seed used in model generation to produce deterministic, reproducible outputs. Using seed 42 ensures that repeated runs with the same prompt and settings yield identical results, isolating differences caused by prompts, persona instructions, or hyperparameters rather than stochastic randomness.

---

### TikToken  
A fast tokenizer from OpenAI that splits text into tokens (units of meaning) and counts them, ensuring prompts fit within an LLMâ€™s context window.

---
