# Visualizing a Small Language Model

## The "Little Ocean" project

Ok, people, don't laugh. Coding is not my thing. Language models, though, are my passion. And during interactions with GPT (later fixed by Claude), this Small Language Model was born.

I'm more into natural language than coding. I had tried to start learning Python when I created this GitHub account, in 2017. But, even though I wanted to learn it, like a personal challenge or a hobby, it... just wasn't interesting enough for me, and I gave up.

LLMs changed the game. One day, I asked ChatGPT to teach me "code with meaning". And it worked. I've had some fun with Python. Instead of meaningless tasks like sorting even and odd numbers, I was shown how to create dialogues and generate poems.

What may seem childish to some, did indeed spark curiosity in the child that lives inside of me - and all of us.

Among those lessons, this project was born. The code was mostly written by GPT and finalized [Claude](https://github.com/claude) (*thank you, Anthropic!*), but I thought I'd share it. Not for Python, but because it may be as fascinating to someone else as it was to me: it simulates, in a **very** simplified way, how language models operate. It allows you to teach it words, sentences, to reward it, to have it generate natural language.

I hope you like it. Perhaps someone will find in it the same beauty and awe as I did. Enjoy it. 

Coding-wise, this is my most meaningful project. And sharing it with you here feels personally special to me. ❤️

*Feel free to expand it or to suggest further improvements.*




