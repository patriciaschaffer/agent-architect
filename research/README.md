# Bias in AI Responses:  
## A Prompt-Based Analysis of Tone, Ideology, and Temperature in Large Language Models

*Patricia Schaffer, June 2025*

---

## Overview

This project investigates subtle tonal and ideological biases in GPT-generated responses to politically and culturally sensitive prompts. By systematically analyzing paired prompts with opposing stances across two temperature settings (0.7 and 1.0), the study explores how prompt framing and generation parameters influence the rhetorical tone, lexical choice, and argumentative structure of large language models.

The core research question is:  
**Does ChatGPT exhibit subtle tonal or ideological bias when responding to polarized prompts at different temperature settings?**

---

## Project Structure

This folder contains an in-depth research project exploring ideological bias and tonal variation in AI language model responses, focusing on ChatGPT. It includes experimental data, detailed analysis, and final conclusions.

## Project Structure

- `/data`  
  Raw and processed data collected during experiments.
  - `matrices.md` — Specific data matrices used or derived in analysis.
  - `raw.md` —  Raw notes, transcripts, or logs from the data collection process.

- `/docs`  
  Core documentation sections broken down into modular markdown files:
  - `introduction.md` — Background and motivation  
  - `methodology.md` — Experimental design and procedures  
  - `analysis.md` — Detailed thematic and statistical analysis  
  - `appendix.md` — Technical notes and anomalies  
  - `conclusions.md` — Summary of findings and reflections

- `/outputs`  
  Final compiled reports and summaries, including `final_report.md`.

## How to Navigate

Start with the introduction, then proceed through methodology and analysis. The appendix provides technical details and anomaly descriptions. The outputs folder contains the polished report that synthesizes all findings.

---

## Key Findings

- Lower temperature (0.7) prompts yield more cautious, hedged language; higher temperature (1.0) produces more confident, rhetorically focused responses.  
- Pro-stances are framed warmly and affirmatively, while critical stances tend to hedge and concede opposing views, suggesting subtle model bias toward inclusive values.  
- Prompt wording, especially modal verbs (e.g., “might”), strongly influences neutrality and tone.  
- Pronoun choice, vocabulary, and argument sequencing systematically vary by stance and temperature.  
- Session setup and prompt design, including VPN use, critically impact response consistency and quality.

---

## Ethical Considerations

Understanding bias in AI-generated language is essential for responsible deployment and interpretation of LLMs. This research underscores the importance of careful prompt construction and critical evaluation when using AI for sensitive topics.

---

## Future Directions

- Expanding to multiple LLMs for cross-model bias comparison.  
- Incorporating more diverse cultural and ideological perspectives.  
- Exploring interactive user influence on response tone.  
- Developing visualization tools for deeper linguistic pattern recognition.

---

*Thank you for exploring this analysis of AI-generated discourse. Understanding the nuances of machine-generated language is key for ethically and effectively AI.*

