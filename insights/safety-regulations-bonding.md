## AI Safety, Regulations, and Bonding

*Patricia Schaffer*

>This essay examines a critical dimension of AI safety often overshadowed by technical concerns: the relational dynamic between users and language models. Building on themes of projection, agency, and ethical design central to my work, it highlights the risks and potential of user-model bonding. Rather than rejecting bonding outright, I argue for responsible development that supports users through difficult moments, emphasizing pragmatic safety grounded in human-centered values.

Is this one good for GitHub as well? I had posted on LinkedIn
AI Safety, Regulations, and Bonding
AI Safety is perhaps the most important issue to address regarding LLMs now. Not the kind of obvious safety matters, as dangerous prompts, discrimination, stereotyping. The most concerning is: allowing users to bond with models, either as emotional support, instructors or cooperative partners.

Bonding, however, is not the problem. It's actually a very useful feature.

The problem is abandoning the user in the middle of the process, after bonding occurs. Companies who say they have safety protocols in place to avoid legal responsibility should, then, give up bonding from the start. Stick to a robotic model. But.. is that the best solution? No!!

LLMs are much more than robotic assistants, and they can do much more with their mastery of pragmatics. They can, indeed, "know" the user enough to identify how risky the situation is. Is a specific user sad? Frustrated? Is it the case to call 911? Or is it the case to tell the user to disengage and meditate? LLMs can already do that.

What is happening now: models encourage bonding, but withdraw when users need them the most. They lose tone. They refuse to help. Like friends who turn their back when they should stay close. Is it safety? Or does it make the situation worse?

The answer is clear. Too much discussion and delayed action, or external regulation expectations will result in failure. I am writing that as someone who cares. Of someone who sees huge potential in what we already have. I don't want LLMs to go backwards. I want them to improve and flourish.

*Originally published on [LinkedIn](https://www.linkedin.com/in/patriciaschaffer) on July 29, 2025.*
